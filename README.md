# Predicci贸n de Churn: Estrategia de Retenci贸n para Interconnect

![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-232F3E?style=for-the-badge&logo=databricks&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)

## Objetivo del Proyecto

El operador de telecomunicaciones **Interconnect** busca evolucionar hacia un modelo de negocio basado en datos. El objetivo de este proyecto es desarrollar un modelo de Machine Learning de clasificaci贸n para **pronosticar la tasa de cancelaci贸n (churn)**. 

Al identificar proactivamente a los usuarios con mayor probabilidad de abandonar el servicio, la empresa puede implementar estrategias de retenci贸n personalizadas, como c贸digos promocionales y planes exclusivos, optimizando as铆 el Customer Lifetime Value (CLV).

## Contexto de Negocio

Interconnect ofrece una infraestructura robusta de servicios digitales que incluye:

* **Conectividad:** Telefon铆a fija multil铆nea e Internet (DSL y Fibra ptica).
* **Servicios de Valor Agregado:** Seguridad en l铆nea, antivirus, soporte t茅cnico y almacenamiento en la nube.
* **Entretenimiento:** Streaming de TV y cat谩logos de pel铆culas.

El modelo analiza c贸mo las preferencias del cliente, el tipo de contrato (mensual, anual o bianual) y los m茅todos de facturaci贸n electr贸nica impactan en la fidelidad a largo plazo.

## Tecnolog铆as y Metodolog铆a

Para este proyecto, se implement贸 un pipeline de Data Science completo:

1.  **Ingenier铆a de Caracter铆sticas:** Consolidaci贸n de datos de m煤ltiples fuentes y creaci贸n de nuevas variables para capturar patrones de comportamiento.
2.  **An谩lisis Exploratorio (EDA):** Visualizaci贸n de tendencias temporales y correlaciones entre servicios contratados y deserci贸n.
3.  **Modelado Predictivo:** Evaluaci贸n y ajuste de hiperpar谩metros de diversos algoritmos:
    * Regresi贸n Log铆stica
    * Random Forest
    * **XGBoost / LightGBM** (Modelos de alto rendimiento)
4.  **M茅tricas de Evaluaci贸n:** Enfoque principal en **AUC-ROC (0.88)** y Accuracy para garantizar un equilibrio entre precisi贸n y sensibilidad.

##  Descripci贸n de los Datos

El an谩lisis se basa en cuatro fuentes de datos principales vinculadas por el `customerID`:

* `contract.csv`: Informaci贸n sobre el tipo de contrato, fechas de inicio/fin, m茅todos de pago y cargos mensuales.
* `personal.csv`: Datos demogr谩ficos del cliente (g茅nero, estado civil, dependencia).
* `internet.csv`: Detalles sobre los servicios de red y seguridad adicionales.
* `phone.csv`: Informaci贸n sobre el uso de l铆neas telef贸nicas m煤ltiples.

*Nota: La informaci贸n del contrato es v谩lida a partir del 1 de febrero de 2020.*

##  Logros del Proyecto

* **Precisi贸n de Predicci贸n:** Se alcanz贸 un **AUC-ROC de 0.88**, superando los umbrales de 茅xito establecidos.
* **Insights Cr铆ticos:** Identificaci贸n de variables clave como el tipo de conexi贸n (Fibra ptica) y el m茅todo de pago como principales predictores del churn.
* **Estrategia:** Generaci贸n de una base s贸lida para que el equipo de marketing tome decisiones basadas en evidencia.

---

###  Contacto
Si tienes inter茅s en discutir este modelo o explorar colaboraciones en Data Science y Log铆stica Anal铆tica, 隆conectemos!

* **LinkedIn:** [https://www.linkedin.com/in/fernando-garza-trevino/]
* **Email:** ferngarzau@gmail.com


## Algunas preguntas y desaf铆os que enfrent茅
**驴Qu茅 pasos del plan se realizaron y qu茅 pasos se omitieron (explica por qu茅)?**
Limpieza: Primero me dedique a la limpieza de los datos esto incluye cambiar los tipos de datos de las columnas a los correctos y eliminar posibles columnas que no son necesarias para el entrenamiento del mismo. De igual manera uni de una manera optima todos los dataframes en uno mismo utilizando el customerID() como indice para luego ya que este todo junto, eliminar dicha columna.  

Exploracion extra: Despues de tener los tipos de datos corregidos, pude hacer un analisis mas extenso y profundo basado en las fechas, valores objetivo y observacion del dataframe general ya junto y limpio, esto incluye analisis de abandonos por fechas, churn rate, graficas que muestran las fechas imoprtantes de abandono y observacion de variables ausentes.

Preparacion del modelo: Utilizamos 4 distintos modelos para explorar la mejora de rendimientos y cual es el tipo de opcion a tomar correcto. En este paso hicimos varias pruebas para determinar el funcionamiento mas optimo de los modelos y como ir mejorandolos.

Resultados: Los resultados mostraron con claridad cual es el modelo con mejor rendimiento y mis recomendaciones a futuro y el mejoramiento de modelos futuros.

Al principio tuve problemas al unir los datos usando el parametro "inner", esto no caus贸 tanto problema por que logr茅 identificar rapido el problema y lo solucione al cambiar al tipo de uni贸n a "outer" que es el correcto para no perder los datos importantes pero ausentes. Otra dificultad que encontr茅 fu茅 al momento de crear los modelos, inicialmente daban un rendimiento muy bajo, es decir, la curva AUC-ROC no daba los resultados esperados ya que no subia de 0.82 de precisi贸n. La solucion que implemente para esto fu茅 experimentar con los par谩metros iniciales de cada modelo para luego decidir a帽adir mejores columnas mediante la pr谩ctica de ingenieria de caracterisiticas y asi de tal manera ayudar a los modelos a centrarse en una linea mas coherente a la hora de producir resultados y nuevas predicciones.

**Pasos Clave**
En mi opini贸n lo que ayud贸 a que los modelos funcionaran muy bien y mejorar谩n su rendimiento fu茅 definitivamente transformar correctamente los datos mediante t茅cnicas como OHE, transformacion de columnas binarias, escalacion estandar (para no afectar los datos de entrenamiento y pulir los sesgos del modelo) y la mas importante, creaci贸n de columnas extras que ayudaron exponencialmente a los modelos a identificar de una manera mas eficaz todas las clases a predecir.

**驴Cu谩l es tu modelo final y qu茅 nivel de calidad tiene?**
Al final fueron 4 modelos: Regresi贸n log铆stica LightGBM Bosque clasificatorio Arbol de decision, el mejor siendo la simple regresion logistica con AUC-ROC de 0.9308 en la prueba y exactitud de 0.8883.
